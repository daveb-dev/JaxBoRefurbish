{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "from jax import random, vmap, lax\n",
    "from jax.config import config\n",
    "from jax.scipy.special import expit as sigmoid\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "\n",
    "from jaxbo.mcmc_models import ReimannianMFGPclassifierFourier, ReimannianGPclassifierFourier\n",
    "from jaxbo.input_priors import uniform_prior\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from utils.Mesh import Mesh\n",
    "import meshio\n",
    "onp.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the left atrium geometry and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mesh('data/LA_geometry.obj')\n",
    "\n",
    "# mesh to voxels factor = 5 (mesh size = 0.2 mm)\n",
    "verts = m.verts*5\n",
    "centroid = verts.mean(0)\n",
    "std_max = verts.std(0).max()\n",
    "verts_new = (verts - centroid)/std_max\n",
    "\n",
    "m = Mesh(verts = verts_new, connectivity = m.connectivity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute Laplacian and its eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Laplacian\n",
      "Computing eigen values\n"
     ]
    }
   ],
   "source": [
    "print('Computing Laplacian')\n",
    "K, M = m.computeLaplacian()\n",
    "print('Computing eigen values')\n",
    "eigvals, eigvecs = eigh(K,M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate all available cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cases\n",
      "['50PF', '50PF-PVI', '50PF-BOX', '70PF', '70PF-PVI', '70PF-BOX', '71PF', '71PF-PVI', '71PF-BOX']\n",
      "names\n",
      "['moderate fibrosis', 'moderate fibrosis - PVI', 'moderate fibrosis - PVI + BOX', 'severe fibrosis - case 1', 'severe fibrosis - case 1 - PVI', 'severe fibrosis - case 1 - PVI + BOX', 'severe fibrosis - case 2', 'severe fibrosis - case 2 - PVI', 'severe fibrosis - case 2 - PVI + BOX']\n",
      "picked case: severe fibrosis - case 1\n"
     ]
    }
   ],
   "source": [
    "ablations = ['', '-PVI', '-BOX']\n",
    "fibrosis = ['50PF', '70PF', '71PF']\n",
    "\n",
    "fibnames = ['moderate fibrosis', 'severe fibrosis - case 1', 'severe fibrosis - case 2']\n",
    "abnames = ['', ' - PVI', ' - PVI + BOX']\n",
    "cases = []\n",
    "names = []\n",
    "\n",
    "for f in fibrosis:\n",
    "    for a in ablations:\n",
    "        cases.append(f + a)\n",
    "\n",
    "for f in fibnames:\n",
    "    for a in abnames:\n",
    "        names.append(f + a)\n",
    "\n",
    "print('cases')\n",
    "print(cases)\n",
    "print('names')\n",
    "print(names)\n",
    "\n",
    "id_case = 3\n",
    "case = cases[id_case]\n",
    "\n",
    "print('picked case:', names[id_case])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data -inducible points- for the selected case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gt = onp.genfromtxt('data/ground_truth_points.csv')[:,3].astype(int)\n",
    "train_points = onp.genfromtxt('data/train_points.csv')[:,3].astype(int)\n",
    "X_L = train_points\n",
    "\n",
    "X_all = X_L\n",
    "\n",
    "N_H = 40 # number of high fidelity points for training\n",
    "\n",
    "X_H = train_points[:N_H]\n",
    "\n",
    "Y_L_all = np.load('data/LF_train-%s.npz' % case)['output']\n",
    "Y_H_all =  np.load('data/HF_train-%s.npz' % case)['output']\n",
    "\n",
    "    \n",
    "Y_L = Y_L_all[:100]\n",
    "Y_H = Y_H_all[:N_H]\n",
    "\n",
    "y_true = np.load('data/ground_truth-%s.npz' % case)['output']\n",
    "\n",
    "X_true = gt\n",
    "\n",
    "Y = np.concatenate([Y_L, Y_H])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select the number of eigenfunctions to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = random.PRNGKey(123)\n",
    "\n",
    "n_eigs = 1000\n",
    "\n",
    "eigpairs = (np.array(eigvals[:n_eigs]), np.array(eigvecs[:,:n_eigs]).T)\n",
    "\n",
    "D = 1\n",
    "lb = 0.0*np.ones(D)\n",
    "ub = 1.0*np.ones(D)\n",
    "bounds = {'lb': lb, 'ub': ub}\n",
    "p_x = uniform_prior(lb, np.ones(D)*m.verts.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-fidelity classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'kernel': 'RBF',\n",
    "           'criterion': 'LW_CLSF', \n",
    "           'input_prior': p_x,\n",
    "           'kappa': 1.0,\n",
    "           'nIter': 0}\n",
    "mcmc_settings = {'num_warmup': 500,\n",
    "                 'num_samples': 500,\n",
    "                 'num_chains': 1,\n",
    "                 'target_accept_prob': 0.9}\n",
    "gp_model = ReimannianMFGPclassifierFourier(options, eigpairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:53<00:00, 18.59it/s, 255 steps of size 1.27e-02. acc. prob=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy: 0.8404074702886248\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch = {'XL': X_L, 'XH': X_H, 'y': Y}\n",
    "key_train, key_test = random.split(rng_key)\n",
    "samples = gp_model.train(batch,\n",
    "                            key_train,\n",
    "                            mcmc_settings,\n",
    "                            verbose = False)\n",
    "\n",
    "rng_keys = random.split(key_test, \n",
    "                    mcmc_settings['num_samples'] * mcmc_settings['num_chains'])\n",
    "kwargs = {'samples': samples,\n",
    "            'batch': batch,\n",
    "            'bounds': bounds,\n",
    "            'rng_key': key_test,\n",
    "            'rng_keys': rng_keys}\n",
    "n_nodes = eigpairs[1].shape[1]\n",
    "X_star = np.arange(n_nodes)\n",
    "\n",
    "\n",
    "# this is a way to speed up the prediction which does not scale well with the amount requested points due to the big size of the covariance matrices\n",
    "Mean, Std = lax.map(lambda x: gp_model.predict_conditional(x, **kwargs),X_star[:3200].reshape(8,-1))\n",
    "mean, std = gp_model.predict_conditional(X_star[3200:], **kwargs)\n",
    "Mean = np.concatenate((np.transpose(Mean, (1,0,2)).reshape((-1,3200)), mean), axis = 1)\n",
    "Std = np.concatenate((np.transpose(Std, (1,0,2)).reshape((-1,3200)), std), axis = 1)\n",
    "\n",
    "Mean_all = Mean.mean(0)\n",
    "Std_all = np.sqrt(np.mean(Std**2, axis = 0))\n",
    "\n",
    "\n",
    "fmesh = meshio.Mesh(points = m.verts*std_max + centroid, cells = {'triangle':m.connectivity}, point_data = {'probs': onp.array(sigmoid(Mean_all)), 'std': onp.array(Std_all)})\n",
    "fmesh.write('output/LA_MF_%s_NH_%i.vtu' % (case, N_H))\n",
    "accuracy = balanced_accuracy_score(y_true, np.rint(sigmoid(Mean_all[X_true])))\n",
    "\n",
    "print('balanced accuracy:', accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single fidelity classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'kernel': 'RBF',\n",
    "           'criterion': 'LW_CLSF', \n",
    "           'input_prior': p_x,\n",
    "           'kappa': 1.0,\n",
    "           'nIter': 0}\n",
    "mcmc_settings = {'num_warmup': 500,\n",
    "                 'num_samples': 500,\n",
    "                 'num_chains': 1,\n",
    "                 'target_accept_prob': 0.9}\n",
    "gp_model_SF = ReimannianGPclassifierFourier(options, eigpairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1000/1000 [00:11<00:00, 87.73it/s, 63 steps of size 5.23e-02. acc. prob=0.95] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy: 0.7504244482173175\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch = { 'X': X_H, 'y': Y_H}\n",
    "key_train, key_test = random.split(rng_key)\n",
    "samples = gp_model_SF.train(batch,\n",
    "                            key_train,\n",
    "                            mcmc_settings,\n",
    "                            verbose = False)\n",
    "\n",
    "rng_keys = random.split(key_test, \n",
    "                    mcmc_settings['num_samples'] * mcmc_settings['num_chains'])\n",
    "kwargs = {'samples': samples,\n",
    "            'batch': batch,\n",
    "            'bounds': bounds,\n",
    "            'rng_key': key_test,\n",
    "            'rng_keys': rng_keys}\n",
    "n_nodes = eigpairs[1].shape[1]\n",
    "X_star = np.arange(n_nodes)\n",
    "\n",
    "\n",
    "# this is a way to speed up the prediction which does not scale well with the amount requested points due to the big size of the covariance matrices\n",
    "Mean, Std = lax.map(lambda x: gp_model_SF.predict_conditional(x, **kwargs),X_star[:3200].reshape(8,-1))\n",
    "mean, std = gp_model_SF.predict_conditional(X_star[3200:], **kwargs)\n",
    "Mean = np.concatenate((np.transpose(Mean, (1,0,2)).reshape((-1,3200)), mean), axis = 1)\n",
    "Std = np.concatenate((np.transpose(Std, (1,0,2)).reshape((-1,3200)), std), axis = 1)\n",
    "\n",
    "Mean_all = Mean.mean(0)\n",
    "Std_all = np.sqrt(np.mean(Std**2, axis = 0))\n",
    "\n",
    "\n",
    "fmesh = meshio.Mesh(points = m.verts*std_max + centroid, cells = {'triangle':m.connectivity}, point_data = {'probs': onp.array(sigmoid(Mean_all)), 'std': onp.array(Std_all)})\n",
    "fmesh.write('output/LA_SF_%s_NH_%i.vtu' % (case, N_H))\n",
    "accuracy = balanced_accuracy_score(y_true, np.rint(sigmoid(Mean_all[X_true])))\n",
    "\n",
    "print('balanced accuracy:', accuracy)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
